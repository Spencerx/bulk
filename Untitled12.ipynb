{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17c690c-5a86-43ec-88f9-73e493ca5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentence-transformers umap-learn embetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184ee7a-18a5-4edd-934f-6d3c16fe9c09",
   "metadata": {},
   "source": [
    "## Intro to bulk\n",
    "\n",
    "In an attempt to come to a quick demo, imagine that this code ran beforehand:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "from sklearn.pipeline import make_pipeline \n",
    "\n",
    "# pip install \"embetter[text]\"\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "# Build a sentence encoder pipeline with UMAP at the end.\n",
    "enc = SentenceEncoder('all-MiniLM-L6-v2')\n",
    "umap = UMAP()\n",
    "\n",
    "text_emb_pipeline = make_pipeline(\n",
    "  enc, umap\n",
    ")\n",
    "\n",
    "# Load sentences\n",
    "sentences = list(pd.read_csv(\"tests/data/text.csv\")['text'])\n",
    "\n",
    "# Calculate embeddings \n",
    "X_tfm = text_emb_pipeline.fit_transform(sentences)\n",
    "\n",
    "# Write to disk. Note! Text column must be named \"text\"\n",
    "df = pd.DataFrame({\"text\": sentences})\n",
    "df['x'] = X_tfm[:, 0]\n",
    "df['y'] = X_tfm[:, 1]\n",
    "\n",
    "X = enc.transform(sentences)\n",
    "```\n",
    "\n",
    "This gives us a dataframe `df` that contains sentences, but also contains 2D UMAP representations of sentence embeddings. We also have a sentence encoder `enc` loaded and we also have access to our original embeddings `X`. Computing these can take a while on a CPU so we will store these on disk.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "np.save(\"utils/X\", X)\n",
    "np.save(\"utils/X_tfm\", X_tfm)\n",
    "df.to_csv(\"utils/df.csv\", index=False)\n",
    "```\n",
    "\n",
    "Given that these are stored on disk, we can boostrap the demo a whole lot quicker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5ba2db-883f-4184-86dc-95d3560b2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae6a77ec-33ec-446d-8db9-147677c93492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.load(\"utils/X.npy\")\n",
    "X_tfm = np.load(\"utils/X_tfm.npy\")\n",
    "df = pd.read_csv(\"utils/df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f196ed-7e72-415b-b749-c5f8be20d99c",
   "metadata": {},
   "source": [
    "Lets use these variables to conjure up a basic text explorer. This will allow us to quickly explore the clusters that appear in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daaf355b-ac0c-4399-be72-647eea085a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf74d2814ba41e093e3c926e07b4556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(Button(button_style='primary', icon='arrows', layout=Layout(width…"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bulk.widgets import BaseTextExplorer\n",
    "\n",
    "widget = BaseTextExplorer(df)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301a2b2-1bec-400f-bc0d-09885e251178",
   "metadata": {},
   "source": [
    "Being able to explore these clusters is neat, but it feels like we might more easily explore everything if we have some more tools at our disposal. In particular, we want to have an encoder around so that we may use queries in our embedded space. \n",
    "\n",
    "The UI below will allow us to explore much more interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48e600-59f8-44fc-acc6-a813b1547e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "enc = SentenceEncoder('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c07e82b7-0735-4c12-bbd0-591efca09436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e3e5ef2210421eabcb9af96fa9c049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='', description='String:', placeholder='Type something'), HBox(childr…"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pay attention here! The rows in df needs to align with the rows in X!\n",
    "widget = BaseTextExplorer(df, X=X, encoder=enc)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7abf74-5dd1-4d14-9d54-3b2422389472",
   "metadata": {},
   "source": [
    "Thanks to tools like ipywidget and anywidget, we can really start building some tools to make the notebook hard to beat as the go-to place for your data needs. My primary interest is to work on tools for data quality and being able to select datapoints in bulk feels like a great place to start. Maybe you can find an interesting subset to annotate first, maybe you get suprised when you see two distinct clusters that should be one. All that good stuff can happen in the notebook.\n",
    "\n",
    "More UI will follow, but this `BaseTextExplorer` feels like a nice place to start!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
